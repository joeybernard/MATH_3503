% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
]{report}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={MATH 3503 - Winter 2025},
  pdfauthor={Joey Bernard},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{MATH 3503 - Winter 2025}
\author{Joey Bernard}
\date{2024-07-05}

\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

These notes are for the Winter 2025 term of the course MATH 3503 at the
University of New Brunswick. These notes will cover more advanced
calculus topics for engineers.

To learn more about Quarto books visit
\url{https://quarto.org/docs/books}.

\bookmarksetup{startatroot}

\chapter{Introduction}\label{introduction}

This is a book created from markdown and executable code.

See @knuth84 for additional discussion of literate programming.

\bookmarksetup{startatroot}

\chapter{First Order ODEs}\label{first-order-odes}

\section{Introduction}\label{introduction-1}

First order Ordinary Differential Equations (ODEs) are the types of
equations that you were exposed to in your first calculus class. These
are derivative functions, made up of first derivatives of one
independent variable. In the most general case, these look like

\(\frac{dy}{dx} = f(x,y)\)

In the special case where f(x,y) is actually only a function of x (i.e.,
f(x,y) = f(x)), then the most general form of a solution looks like

\(y(x) = \int f(x) dx\)

In this section, we will look at various techniques that can be used to
solve other forms of first order ODEs. In all of the following cases, we
may or may not have an initial condition. When we do, this initial
condition can be used to determine any constants of integration that pop
up during calculating the solution.

\section{Seperable ODEs}\label{seperable-odes}

One of the simplest forms of first order ODE is the seperable form. This
happens when you can write the differential equation in the form of

\(y^{'} = f(x) g(y)\)

When you have an equation that looks like this, you can rearrange it to
look like

\(\frac{dy}{dx} = f(x) g(y) \\
\frac{1}{g(y)} dy = f(x) dx\)

Solving the equation becomes as simple as integrating both sides of the
rearranged equation.

\(\int \frac{1}{g(y)} dy = \int f(x) dx\)

\section{Linear Equations and Integrating
Factors}\label{linear-equations-and-integrating-factors}

The next step in complexity for first order ODEs is if we have an extra
function of x and y. The general form in this case looks like

\(y^{'} + p(x) y = f(x)\)

This type of equation is considered linear because there are no higher
powers of \(y\) or \(y^{'}\). In order to solve these types of
equations, we need to use an integrating factor, defined by

\(I(x) = e^{\int p(x) dx}\)

This extra factor can now get used in solving the differential equation
by plugging it into

\(y = \frac{1}{I(x)} \int I(x) * f(x) dx\)

\section{Exact/Homogeneous}\label{exacthomogeneous}

Exact equations are special first order ODEs that are derived from a
potential function. These are common types of equations that occur in
physics and engineering. In these types of cases, you have a potential
field that defines the behaviour described by the differential equation.
In the general case, we may have the potential defined by

\(F(x,y)\)

In this general case, we can look at the total derivative of F(x,y).

\(dF = \frac{\partial F}{\partial x} dx + \frac{\partial F}{\partial y} dy\)

This should look familiar from the MATH 2513 class, when you covered
partial differential equations. We can use shorter nomenclature and
rewrite this as

\(dF = M(x,y) dx + N(x,y) dy\)

If we assume that the potential function is a constant function, then we
know that \(dF = 0\), and we can rewrite our equation as

\(M(x,y) dx + N(x,y) dy = 0\)

This nows looks like something that we may run into when working with
first order ODEs. Specifically, this is a homogeneous ODE. If we can
write our problem equation in this form, we can work backwards to
discover what the solution is. The first step is to integrate either M
or N. You usually pick whichever one is simpler to work with. In the M
case, we end up with

\(F = \int M dx + C(y)\)

The important part is the extra term of C(y). You then take this
solution for F(x,y) and take the derivative with respect to y. You then
set this equal to N, in order to solve for what C(y) is. You can also
start by integrating N first, and you end up with an extra term of C(x).

\(F = \int N dy + C(x)\)

We can now take the derivative with respect to x and set it equal M. In
this way, we can solve for C(x).

In some cases, an equation of the form

\(M dx + N dy = 0\)

actually isn't exact. If we aren't sure, we can test for exactness by
checking to see if we have

\(\frac{\partial M}{\partial y} = \frac{\partial N}{\partial x}\)

This comes from the fact that both M and N are partial derivatives of
the potential function F. If you remember from MATH 2513, we have

\(\frac{\partial M}{\partial y} = \frac{\partial N}{\partial x} \\
\frac{\partial^2 F}{\partial y \partial x} = \frac{\partial^2 F}{\partial x \partial y}\)

So, if we fail this test, what can we do? In these cases, we can
multiply by an integrating factor to get it into an exact form. There is
a derivation of how to get the following equation, but we can use

\(P(x) = \frac{M_y - N_x}{N}\)

to find a function. This becomes our integrating factor, that we can
substitute into

\(e^{\int P(x) dx} (M dx + N dy) = 0\)

This new equation is now exact, and we can use the above technique to
solve for a solution.

\section{Bernoulli}\label{bernoulli}

There are several classes of equations where we can use a change of
variable to help make the differential equation simpler to solve. One of
these types are Bernoulli equations. These have a general form of

\(y^{'} + p(x) y = q(x) y^{n}\)

In this case, we can start by dividing out both sides of the equation by
\(y^{n}\). This gives us

\(y^{-n} y^{'} + p(x) y^{1-n} = q(x)\)

We can now do a change of variables to

\(u = y^{1-n}\)

with the first derivative being

\(u^{'} = (1-n) y^{-n} y^{'}\)

Substituting this back into the original differential equation, we end
up with

\(\frac{u^{'}}{(1-n) y^{-n}} + p(x) u = q(x)\)

The resulting new differential equation will then need to be solved
using one of the other techniques you learned. In some cases, it may be
seperable, in some cases you may need to use an integrating factor. Once
you have a solution for u, you can then substitute it back into the
change of variable you did above.

\bookmarksetup{startatroot}

\chapter{Second Order ODEs}\label{second-order-odes}

Second order ODEs are differential equations where we may have second
derivatives of y with respect to x. The general form looks like

\(A(x) y^{''} + B(x) y^{'} + C(x) y = F(x)\)

Usually, we divide through so that the \(y^{''}\) term is all by itself.
If we do this, we end up with

\(y^{''} + p(x) y^{'} + q(x) y = f(x)\)

\section{Homogeneous with Constant
Coefficients}\label{homogeneous-with-constant-coefficients}

The first class of second order ODEs we will look at are homogeneous
equations. This is the special case of setting \(f(x) = 0\). We will
also further constrain the equations for this section by only looking at
constant coefficients. This special case looks like

\(y^{''} + b y^{'} + c y = 0\)

In the most general case, there should be two linearly independent
solutions (\(y_1 and y_2\)) that combine to make the general solution.
This general solution looks like

\(y = C_1 y_1 + C_2 y_2\)

You can check for linear independence by using the Wronskian. If we have
linear independence, then we have

\(\begin{vmatrix}
y_1 & y_2 \\
y^{'}_1 & y^{'}_2
\end{vmatrix} \ne 0\)

In order to find these two solutions to the differential equation, we
start by setting up the characteristic equation that is associated with
the differential equation. This characteristic equation is given by

\(a r^2 + b r + c = 0\)

We can then find out what the two values for r are. Because this is just
a quadratic equation, it is simply

\(r_1,r_2 = \frac{-b \pm \sqrt{b^2 - 4 a c}}{2 a}\)

There are three cases when solving for r.

\begin{itemize}
\item Case 1 - $r_1$ and $r_2$ are real and unique
\item Case 2 - $r_1$ and $r_2$ are equal
\item Case 3 - $r_1$ and $r_2$ are complex
\end{itemize}

\subsection{Case 1}\label{case-1}

If we have case 1, we can easily construct our solution. In this case,
it would look like

\(y = C_1 e^{r_1 x} + C_2 e^{r_2 x}\)

\subsection{Case 2}\label{case-2}

If we have case 2, we can't simply use the same method as for case 1. We
would end up with two equal equations. In this case, we can separate
\(y_1\) and \(y_2\) by multiplying one of them by x. This would give us
the solution

\(y = C_1 e^{r x} + C_2 x e^{r x}\)

\subsection{Case 3}\label{case-3}

Case 3 is a new one if you have never considered the imaginary case for
the quadratic equation. In this case, the solution to the characteristic
equation is

\(r_{1,2} = \alpha \pm \beta i\)

In this case, we use the real and imaginary parts of r to make up our
solution for y. The general form becomes

\(y = C_1 e^{\alpha x} cos(\beta x) + C_2 e^{\alpha x} sin(\beta x)\)

\section{Initial Value Problem}\label{initial-value-problem}

In all of the above cases, we would have constants of integration that
would show up in the solutions. In the first order ODE case, a single
initial value is enough to define the constant of integration that
appears. In the second order case, we will need two initial values.
These take the form of

\(y(x_0) = y_0 \\
y^{'}(x_0) = y^{'}_0\)

These can be plugged into the general solution for y to find a
particular solution.

\section{Non-homogeneous Differential Equations with Constant
Coefficients}\label{non-homogeneous-differential-equations-with-constant-coefficients}

Up to now, we have been working with homogeneous equations where f(x)=0.
In many physical situations, we end up with a non-homogeneous
differential equation. The f(x) term is often called a driving function
or forcing function.

In order to solve these types of equations, we start by assuming that
the equation is homogeneous. In this way, we can find a complimentary
solution, \(y_c\) that solves the equation when we pretend that f(x)=0.
The second step is to come up with a second solution, \(y_p\), called
the particular solution. We will look at two options of finding this
particular solution.

\subsection{Undetermined Coefficients}\label{undetermined-coefficients}

The first method is to use the method of undetermined coefficients. The
first step is to find \(y_c\). This is done by assuming that the ODE is
actually homogeneous, or of the form

\(a y^{''} + b y^{'} + c y = 0\)

In this case, we can set up a characteristic equation that is associated
with the homogeneous version of our ODE.

\(a r^2 + b r + c = 0\)

We now need to solve for the values of r, using this basic quadratic
equation. The solution is given by

\(r = \frac{-b \pm \sqrt{b^2 - 4 a c}}{2 a}\)

This gives us three cases for possible values of r.

\subsubsection{Case 1}\label{case-1-1}

In this case, both values of r are real and unique. For this case, we
have a solution of y given by

\(y = C_1 e^{r_1 x} + C_2 e^{r_2 x}\)

\subsubsection{Case 2}\label{case-2-1}

In this case, r is real, but both values are equal. In this case, we
need to adjust one of the possible terms for y so that everything stays
linearly independent. We then get

\(y = C_1 e^{r x} + C_2 x e^{r x}\)

\subsubsection{Case 3}\label{case-3-1}

In this case, we end up with complex values for r, of the form

\(r = \alpha \pm \beta i\)

This leads to solutions for y as given by

\(y = C_1 e^{\alpha x} cos(\beta x) + C_2 e^{\alpha x} sin(\beta x)\)

Once we have this solution for the homogeneous version, we need to find
the extra part to account for the right hand side of the equation, f(x).
This extra part is called the driving function or forcing function. We
actually make a guess based on the form of f(x). The table below covers
the standard types of f(x) that we tend to run into.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\(f(x)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(y_p\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(a x + b\) & \(A x + B\) \\
\(a x^2 + b x + c\) & \(A x^2 + B x + C\) \\
\(a sin(b x)\) & \(A sin(b x) + B cos(b x)\) \\
\(a cos(b x)\) & \(A cos(b x) + B sin(b x)\) \\
\(a e^{b x}\) & \(A e^{b x}\) \\
\((a x + b) e^{c x}\) & \((A x + B) e^{c x}\) \\
\(a e^{b x} sin(c x)\) & \(A e^{b x} sin(c x) + B e^{b x} cos(c x)\) \\
\((a x^2 + b x + c) e^{d x} cos(\pi x)\) &
\((A x^2 + B x + C) e^{d x} cos(\pi x) + (D x^2 + E x + F) e^{d x} sin(\pi x)\) \\
\(a x + e^{b x}\) & \(A x + B + C e^{b x}\) \\
\(a + e^{b x}\) & \(A + B e^{b x}\) \\
\(a e^{b x} + c sin(d x)\) & \(A e^{b x} + C sin(d x) + D cos(d x)\) \\
\(a x^2 + b cos(c x)\) &
\(A x^2 + B x + C + D cos(c x) + E sin(c x)\) \\
\end{longtable}

In order to find the coefficients, you would take the first and second
derivatives of your guess and plug it into the origianl equation in
question. Setting this equal to f(x), you can then compare terms from
the left hand side to the equivalent terms on the right hand side to
find each of the coefficients. This then gives you the \(y_p\) part of
the general solution.

\emph{NOTE} - You need to make sure that \(y_c\) and \(y_p\) are
linearly independent. If they aren't, you can multiply \(y_p\) by some
power of x in order to make the solutions linearly independent.

\subsection{Variation of Parameters}\label{variation-of-parameters}

In order to use variation of parameters, you start the same way as above
to find the \(y_c\) solution. Once you have that, you will have two
partial solutions \(y_1\) and \(y_2\), since we have

\(y_c = C_1 y_1 + C_2 y_2\)

The second solution is given by

\(y_p = u_1 y_1 + u_2 y_2\)

In order to find \(u_1\) and \(u_2\), we use the following formulas:

\(u_1^{'} = \frac{
\begin{vmatrix}
0 & y_2 \\
f(x) & y_2^{'}
\end{vmatrix}}{\begin{vmatrix}
y_1 & y_2 \\
y_1^{'} & y_2^{'}
\end{vmatrix}}\)

and

\(u_2^{'} = \frac{
\begin{vmatrix}
y_1 & 0 \\
y_1^{'} & f(x)
\end{vmatrix}}{\begin{vmatrix}
y_1 & y_2 \\
y_1^{'} & y_2^{'}
\end{vmatrix}}\)

Once you integrate these to get \(u_1\) and \(u_2\), you can plug them
back into \(y_p\).

\bookmarksetup{startatroot}

\chapter{Systems of ODEs}\label{systems-of-odes}

\section{Introduction}\label{introduction-2}

In many realistic cases, we don't simply have a single dependent
variable. In many real situations, we may have multiple equations in
several dependent variables. This section of the course will cover the
techniques and pratices to help solve these types of systems of
equations.

\section{Ideas and Notation}\label{ideas-and-notation}

The basic idea in these methods is to convert a higher order ODE into a
system of 1st order ODEs. We will be looking at just homogeneous ODEs
for this section. This is done by introducing a new set of variables for
each of the new ODEs. For example, say we had an original 3rd order ODE
given by

\(u^{'''} + a u^{''} + b u^{'} + c u = 0\)

We could replace this with

\(\begin{multiline}
y_1 = u \\
y_2 = u^{'} = y_1^{'} \\
y_3 = u^{''} = y_2^{'} \\
y_4 = u^{'''} = y_3^{'}
\end{multiline}\)

This would give us the system

\(\begin{multiline}
y_3^{'} = -a y_3 - b y_2 - c y_1 \\
y_2^{'} = y_3 \\
y_1^{'} = y_2
\end{multiline}\)

With everything in order like this, this is called the normalized form.
We can also write this in a matrix form, as

\(Y^{'} = A Y\)

where we have

\(Y^{'} = \begin{bmatrix} y_1^{'} \\ y_2^{'} \\ ... \end{bmatrix}\)

\(A = \begin{bmatrix} a_{11} & a_{12} & ... \\ a_{21} & a_{22} & ... \\ ... & ... & ... \end{bmatrix}\)

\(Y = \begin{bmatrix} y_1 \\ y_2 \\ ... \end{bmatrix}\)

Solutions to these systems are always found over some interval
\(I = [a,b]\). It is importnat to know whether these solutions are
linearly independent or not. In order to test this, we can check the
Wronskian, given by

\(W[Y_1, Y_2, Y_3, ...] = | Y_1 Y_2 Y_3 ... | \ne 0\)

If we have a set of solutions that are linearly independent, then this
becomes the fundamental set of solutions. This fundamental set of
solutions can be combined into a matrix, of the form

\(\Phi = [ Y_1 Y_2 Y_3 ...]\)

called the fundamental matrix.

\section{Eigenvalue Method Examples}\label{eigenvalue-method-examples}

In order to solve these types of systems of ODEs, we assume that the
solution will be of the form

\(Y = V e^{\lambda t}\)

where \(\lambda\) is an eigenvalue and \(V\) is the associated
eigenvector. If we plug this into our system, we get

\(\begin{multiline}
Y^{'} = A Y \\
V \lambda e^{\lambda t} = A V e^{\lambda t} \\
A V - \lambda V = 0 \\
(A - \lambda I) V = 0
\end{multiline}\)

This means that if we solve the problem

\(A - \lambda I = 0\)

this is equivalent to solving the original system of ODEs.

We have three possible cases when solving this new problem: - case 1 :
real and distinct eigenvalues - case 2 : real and at least some repeated
eigenvalues - case 3 : at least 1 complex eigenvalue

For case 1, we can simply find the associated eigenvector for each
unique eigenvalue, and this gives us our set of solutions.

For case 2, where we have at least one repeated eigenvalue, we need to
do something a little different.

\section{Vector Fields}\label{vector-fields}

\section{Second Order Systems}\label{second-order-systems}

\section{Repeated Eigenvalues}\label{repeated-eigenvalues}

\section{Matrix Exponentials}\label{matrix-exponentials}

\section{Non-homogeneous Equations}\label{non-homogeneous-equations}

\bookmarksetup{startatroot}

\chapter{Fourier Series}\label{fourier-series}

\section{Boundary Value Problem}\label{boundary-value-problem}

\section{Orthogonality of
Eigenfunctions}\label{orthogonality-of-eigenfunctions}

\section{Eigenfunction Decomposition and Trigonometric
Series}\label{eigenfunction-decomposition-and-trigonometric-series}

\section{Sawtooth and Square Wave
Examples}\label{sawtooth-and-square-wave-examples}

\section{More Series}\label{more-series}

\bookmarksetup{startatroot}

\chapter{Laplace Transforms}\label{laplace-transforms}

\section{Introduction}\label{introduction-3}

\section{Examples}\label{examples}

\section{Inverse Laplace Transform}\label{inverse-laplace-transform}

\section{Solving Homogeneous ODEs}\label{solving-homogeneous-odes}

\section{Solving Non-homogeneous
ODEs}\label{solving-non-homogeneous-odes}

\section{Unit Step Function}\label{unit-step-function}

\section{More Transforms of ODEs}\label{more-transforms-of-odes}

\section{Convolution}\label{convolution}

\section{Impulse Functions}\label{impulse-functions}

\bookmarksetup{startatroot}

\chapter{Summary}\label{summary}

In summary, this book has no content whatsoever.




\end{document}
